# Answering questions by learning to rank - Learning to rank by answering questions

- **author**:George-Sebastian Pîrtoacă,  Traian Rebedea,  Ștefan Rușeți 
- **abstract**: Answering multiple-choice questions in a setting in which no supporting documents are explicitly provided continues to stand as a core problem in natural language processing. The contribution of this article is two-fold. First, it describes a method which can be used to semantically rank documents extracted from Wikipedia or similar natural language corpora. Second, we propose a model employing the semantic ranking that holds the first place in two of the most popular leaderboards for answering multiple-choice questions: ARC Easy and Challenge. To achieve this, we introduce a self-attention based neural network that latently learns to rank documents by their importance related to a given question, whilst optimizing the objective of predicting the correct answer. These documents are considered relevant contexts for the underlying question. We have published the ranked documents so that they can be used off-the-shelf to improve downstream decision models. 
- **keywords**:
- **interpretation**:待补充
- **pdf**: [pdf](https://arxiv.org/pdf/1909.00596)
- **code**:[code](https://github.com/SebiSebi/AI2-Reasoning-Challenge-ARC/tree/master/AttentiveRanker/documents)
- **dataset**:ARC Easy,ARC Challenge
- **ppt/video**:
- **curator**: Yawen Dai