# Neural Entity Summarization with Joint Encoding and Weak Supervision
* **author**: Junyou Li, Gong Cheng, Qingxia Liu, Wen Zhang, Evgeny Kharlamov, Kalpa Gunaratna, Huajun Chen
* **abstract**: In a large-scale knowledge graph (KG), an entity is often described by a large number of triple-structured facts. Many applications require abridged versions of entity descriptions, called entity summaries. Existing solutions to entity summarization are mainly unsupervised. In this paper, we present a supervised approach NEST that is based on our novel neural model to jointly encode graph structure and text in KGs and generate high-quality diversified summaries. Since it is costly to obtain manually labeled summaries for training, our supervision is weak as we train with programmatically labeled data which may contain noise but is free of manual work. Evaluation results show that our approach significantly outperforms the state of the art on two public benchmarks.
* **keywords**: weak supervision, entity summaries
* **interpretation**: [来源: NJU websoft](http://ws.nju.edu.cn/blog/2020/04/websoft%e6%8a%80%e6%9c%af%e7%bb%8f%e9%aa%8c%e5%88%86%e4%ba%ab-ijcai-pricai20%e8%ae%ba%e6%96%87%e4%bb%8b%e7%bb%8d-neural-entity-summarization-with-joint-encoding-and-weak-supe/)
* **pdf**: [link](https://www.ijcai.org/Proceedings/2020/242)
* **code**: [link](https://github.com/nju-websoft/NEST)
* **dataset**: Entity Summarization BenchMark (ESBM), FACES Evaluation Dataset (FED) 
* **ppt/video**:
* **curation**: Jiong Zhang 