# Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension

* **author**ï¼šRajarshi Das, Tsendsuren Munkhdalai, Xingdi Yuan, Adam Trischler, Andrew McCallum
* **abstract**: We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.
* **keywords**: recurrent graph networks, dynamic knowledge base construction, entity state tracking, machine reading comprehension
* **interpretation**: 
* **pdf**:  [link](https://openreview.net/pdf?id=S1lhbnRqF7)
* **code**: 
* **dataset**: PROPARA
* **ppt/video**: 
* **curator**: Chang Liu
