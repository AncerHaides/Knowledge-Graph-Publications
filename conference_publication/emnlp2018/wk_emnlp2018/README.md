## Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space

**author**:Koki Washio,Tsuneaki Kato

**abstract**:Capturing the semantic relations of words
in a vector space contributes to many natural language processing tasks. One promising approach exploits lexico-syntactic patterns as features of word pairs. In this paper, we propose a novel model of this
pattern-based approach, neural latent relational analysis (NLRA). NLRA can generalize co-occurrences of word pairs and lexicosyntactic patterns, and obtain embeddings of the word pairs that do not co-occur. This
overcomes the critical data sparseness problem
encountered in previous pattern-based models. Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous pattern-based models. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-theart model that exploits additional semantic relational data.

**keywords**:

**interpretation**:

**pdf**:[paper](https://www.aclweb.org/anthology/D18-1058.pdf)

**code**:

**dataset**:

**ppt/video**:

**curator**:Ranran Chu