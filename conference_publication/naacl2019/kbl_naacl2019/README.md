# Text Generation from Knowledge Graphs with Graph Transformers
* **author**: Rik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, Hannaneh Hajishirzi
* **abstract**: Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.
* **keywords**: 
* **interpretation**: [OpenKG]( https://mp.weixin.qq.com/s/xJ05ctlYhyVy__6CaOm4WQ)
* **pdf**: [paper](https://www.aclweb.org/anthology/N19-1238.pdf)
* **code**: [github](https://github.com/rikdz/GraphWriter)
* **dataset**: AGENDA
* **ppt/video**: 
* **curation**: Xiaoyu Shang
